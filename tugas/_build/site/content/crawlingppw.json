{"version":3,"kind":"Notebook","sha256":"ea5e10260fb50acf094045f1ab6086834b72e1ad5759c1781c5c18ce7ffdc598","slug":"crawlingppw","location":"/CrawlingPPW.ipynb","dependencies":[],"frontmatter":{"title":"Crawling Penambangan Web","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3"},"authors":[{"nameParsed":{"literal":"Ahya","family":"Ahya"},"name":"Ahya","id":"contributors-PPW2\\tugas\\myst-generated-uid-0"}],"github":"https://github.com/ahyaac/PPW2","exports":[{"format":"ipynb","filename":"CrawlingPPW.ipynb","url":"/CrawlingPPW-085ede3ae1f63563acfe6816456bd100.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5KbNfiKQX9qS","outputId":"45ae42b8-f6cc-4d6d-a882-acfc385ad3eb"},"children":[{"type":"code","lang":"python","executable":true,"value":"pip install sprynger","identifier":"5kbnfikqx9qs-code","enumerator":"1","html_id":"id-5kbnfikqx9qs-code","key":"u3ZwLc7kTt"},{"type":"outputs","id":"ZIWDaKn_XK1sysWDHZdMw","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: sprynger in /usr/local/lib/python3.12/dist-packages (0.4.1)\nRequirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sprynger) (5.4.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from sprynger) (2.32.4)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from sprynger) (2.5.0)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from sprynger) (4.3.8)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->sprynger) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->sprynger) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->sprynger) (2025.8.3)\n"},"children":[],"identifier":"5kbnfikqx9qs-outputs-0","html_id":"id-5kbnfikqx9qs-outputs-0","key":"J8OznVvV40"}],"identifier":"5kbnfikqx9qs-outputs","html_id":"id-5kbnfikqx9qs-outputs","key":"dbq0YSmiEz"}],"identifier":"5kbnfikqx9qs","label":"5KbNfiKQX9qS","html_id":"id-5kbnfikqx9qs","key":"hIIY0uLqIF"},{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JeD1ERHxYSH3","outputId":"2b3b803f-70fb-4b23-d55b-e9fceecb1478"},"children":[{"type":"code","lang":"python","executable":true,"value":"import requests\n# Silahkan membuat api key dari https://dev.springernature.com/#api\napi_key = \"6812f052d58306c4316bac37cf837912\"\nkeyword = \"web mining\"\n\nurl = \"https://api.springernature.com/meta/v2/json\"\nparams = {\n    \"q\": f\"keyword:{keyword}\",\n    \"api_key\": api_key,\n    \"p\": 10\n}\n\nresponse = requests.get(url, params=params)\n\nif response.status_code == 200:\n    data = response.json()\n    print(f\"Total hasil: {data['result'][0]['total']}\\n\")\n    for record in data['records']:\n        doi = record.get('doi', 'N/A')\n        title = record.get('title', 'No title')\n        abstract = record.get('abstract', 'No abstract')\n        print(f\"DOI: {doi}\")\n        print(f\"Title: {title}\")\n        print(f\"Abstract: {abstract}\\n\")\nelse:\n    print(\"Error:\", response.status_code, response.text)","identifier":"jed1erhxysh3-code","enumerator":"2","html_id":"jed1erhxysh3-code","key":"OHidOTDMIy"},{"type":"outputs","id":"Ii6XtHVhx8UFBbjXq6FfD","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Total hasil: 7596\n\nDOI: 10.1007/978-3-031-89518-0_1\nTitle: On the Centrality of Web Trackers: Assessing Its Potential for Automated Detection\nAbstract: For the past 20 years, web tracking has raised worries among privacy advocates and authorities responsible for data protection. Researchers have proposed several machine learning-driven remedies to identify Web trackers in an automated manner. While those have displayed potential, they have primarily remained as proofs-of-concept. This work extends on t.ex-Graph outlined in our previous work [ 36 ]. The aim of this model is to distinguish benign from tracking hosts by considering their centrality in the network, and data flows to them. Based on the results of our previous work, we abandoned the SLD-based approach. Consequently, we made slight modifications to the feature vector. Our classifier’s performance is comparable to its original version, and we tested its cross-browser and longitudinal performance. Our results indicate that while the cross-browser performance significantly decreases, the longitudinal performance maintains a high level.\n\nDOI: 10.1007/978-3-031-93257-1_6\nTitle: Adaptive Web API Recommendation via Matching Service Clusters and Mashup Requirement\nAbstract: With the rapid proliferation of Web services and Web APIs, recommendation systems can effectively address the issue of information overload and alleviate the burden of meaningless filtering. Existing approaches can help filtering appropriate Web services for mashup creation, however, they often fall short of developers’ different and personalized needs by recommending only a fixed number of APIs and lack precision in aligning mashup requirements across all categories. To solve the above issue, this paper introduces a novel Web service recommendation framework called AWAR for mashup creation, which focuses on the matching strategy between mashup requirements and Web APIs, and enhances recommendation effectiveness by integrating natural language processing, optimization algorithms, and deep learning. Extensive experiments conducted on large-scale real datasets demonstrate that the proposed approach receives superior recommendation results on multiple evaluation metrics compared to advanced competing baselines.\n\nDOI: 10.1007/978-3-031-94280-8_1\nTitle: IoT-Enabled Child Monitoring and Control System via Web Interface\nAbstract: In this fast-paced society, working parents nowadays find it challenging to juggle childcare with their busy schedules. In light of this, a novel infant management system utilizing the Internet of Things has developed. This system functions by using sophisticated technology to automate tasks hence ensuring babies safety and comfort. The major features are sound sensor that results into automatic rocking cradle; integrated speaker which can play lullabies to a baby. The system is continuously monitored for its temperature and humidity by sensors sending the caregiver a summary notification about their vicinity while motion detectors are present alongside it. While a rain sensor identifies wet diapers, a DC fan keeps the room at a suitable temperature. Components like cradle swing, DC fan operations, or even playing of lullabies can be remotely controlled through web interface. It implies that one can easily control his infant immediate surroundings from anywhere around the world without hassle. The proposed system utilizes ESP32 technology making use of ESP32 camera for detecting children via live streaming. This all-inclusive monitoring has provided a new dimension to childcare technology thus relieving anxiety among workers as well as inexperienced parents.\n\nDOI: 10.1007/978-3-032-00350-8_12\nTitle: Ethical Implications of Using AI to Monitor and Regulate Dark Web Activities\nAbstract: The dark web continues to attract more illegal activities, and law enforcement and societal security face significant challenges. AI, though strong for monitoring and regulation, does raise critical ethical concerns concerning the use of these technologies for that purpose. This study considers the ethical aspects of AI systems for policing the dark web, including the trade-off between security and privacy, risks of bias and discrimination, and accountability in automated decision-making. Through a mixed-method approach involving both legal analysis, expert interviews, and case studies of existing AI-driven dark web monitoring systems, we identify central ethical challenges and potential mitigation strategies. In doing so, our results will reflect how AI may strengthen efficiency and effectiveness in terms of dark web policing, which equally result in the violation of user privacy, the perpetuation of systemic biases, and a lack of transparency in its operations. Ultimately, we conclude that proper use of AI in monitoring dark webs requires a robust governance framework, one that can ensure accountability, legitimacy, and respect for civil liberties. Such a framework must build on robust, clear guidelines for collecting and utilizing information, regular audits of bias, effectiveness, and mechanisms for human oversight and intervention. Given such measures, chances for using AI in the fight against crimes committed on the dark web are securely positioned within the right and constitutional means to protect the rights of individuals in this age of digitization.\n\nDOI: 10.1007/978-3-031-97144-0_6\nTitle: IRIS: Rapid Curation Framework for Iterative Improvement of Noisy Named Entity Annotations\nAbstract: We propose IRIS (IteRative Improvement dS-ner), a rapid curation framework for the iterative improvement of noisy named entity annotations. The framework aims to provide an efficient and rapid method for curating noisy entity annotations initially made by distantly supervised named entity recognition (DS-NER). Unlike many existing entity annotation tools, which focus primarily on annotation from scratch, IRIS is designed to provide more efficient methods for improving entity annotations initially generated by DS-NER. This is enabled by robust annotation search capabilities and the automatic annotation capabilities suggested by the NER model, which is initialized with the DS-NER model and later incrementally updated during annotation. We also adopt Active Learning (AL), which allows curators to work with documents suggested by the system, rather than manually selecting them. This work also analyzes the trade-offs among different strategies for iteratively updating the NER model, such as selecting training samples and the strategies for fine-tuning the new NER model based on the previous model or training it from scratch.\n\nDOI: 10.1007/s10115-025-02444-z\nTitle: Cross-modal associated learning with spatial–temporal attention for hot topic detection\nAbstract: With the explosion in the number of web videos, it has become a common practice to detect hot topics with web videos. However, each video clip contains multiple patterns, in which object actions might only appear in specific spatial areas or specific time periods, posing a huge challenge for web video hot topic detection. Fortunately, visual information during a specific time period and area will significantly enhance the rapid capture of key information, which is particularly important for detecting hot topics. Therefore, we propose a cross-modal associated learning method with spatial–temporal attention. It can automatically select discriminative time segments to detect hot topics by focusing on spatial regions with rich information. Firstly, after focusing on important keyframes related to the topic through temporal attention, spatial attention emphasizes the salient regions in the frame, thus incorporating discriminative features at the spatial level. Secondly, after integrating text structure knowledge into text semantic features, it can adaptively learn the weights of text features and visual features. Thirdly, adaptive learning of cross-modal fusion weights, achieving mutual guidance between text and visual information in attention dispersed association models to enhance feature learning. Finally, under the constraint of contrast loss, hot topics are detected with the similarity between features. Extensive experiments conducted on web videos from YouTube indicate that our method outperforms 8 leading state-of-the-art methods.\n\nDOI: 10.1007/s40558-025-00327-1\nTitle: A recommender-based web platform to boost tourism in marginal territories\nAbstract: Recommender engines are software applications employed in online tourism information searches to suggest useful content and guide user choices. They represent a significant area of research within the tourism sector, crucially influencing traveler decisions through personalized recommendations. This paper focuses specifically on the Branding4Resilience (B4R) project, whose objective is to promote inner areas, by co-designing virtuous transformations with their inhabitants through novel branding strategies and digital enabling infrastructures. All experiments and assessments described in this study were conducted within the italian area of Sassoferrato, corresponding to the criteria defined by the B4R initiative. The paper introduces a dedicated web platform aimed at enhancing tourism by directing attention towards inland destinations and networking opportunities. The platform enables local providers of tourism-related services, such as guides, event organizers, and restaurateurs, to connect effectively with tourists seeking distinctive experiences. By facilitating interactions, the platform promotes collaboration, innovation, and the co-creation of personalized experiences, transforming tourists into active participants and contributors. To evaluate user experience, perceived usefulness, and innovation of the platform, we analyzed user responses to a structured questionnaire, which combined frequently addressed questions from existing literature with newly developed items specific to our platform. Constructs included tourist platform usage, perceived utility, content quality, design and usability, and innovative elements. The implemented algorithm demonstrated an average sensitivity of 79.74%, highlighting its efficacy in providing relevant suggestions to the platform’s “consumers” users.\n\nDOI: 10.1186/s40793-025-00772-9\nTitle: Protozoa-driven micro-food webs shaping carbon and nitrogen cycling in reservoir ecosystems\nAbstract: Protozoa-driven micro-food webs are pivotal regulators of microbial community structure and carbon–nitrogen cycling. By mediating trophic cascades that regulate bacterial and algal populations, protozoa influence nutrient remineralization and energy flow. Their regulation is crucial for stabilizing biogeochemical processes and preventing harmful algal blooms. However, little is known about the detailed relationship between the traits of micro-food webs and carbon/nitrogen cycling processes. Using metagenomic data, we investigated the complexity and stability of micro-food webs in three distinct zones of the Fenhe Reservoir—the inflow river zone, shallow wetland, and deep-water zone—to assess their impacts on carbon and nitrogen cycling. Our findings revealed distinct spatial patterns in micro-food web complexity and stability, with the highest diversity and interaction density in inflowing river zones and a gradual simplification towards deep-water zones. Functional gene analysis shows significant differences in carbon degradation, fixation pathways, and nitrogen transformation processes, with shallow waters exhibiting strong microbial-mediated nitrification and denitrification, while deep waters rely on anaerobic nitrogen reduction pathways. Partial least squares path modeling (PLS-PM) indicated that protozoan-driven micro-food web structures regulate microbial functional differentiation, thereby influencing carbon and nitrogen cycle. Additionally, environmental parameters such as organic carbon concentration and nitrogen availability significantly shape microbial interactions and biogeochemical transformations. These findings highlight the intricate relationship between microbial community composition, food web stability, and elemental cycling, providing critical insights for reservoir ecosystem management and water quality optimization.\n\nDOI: 10.1186/s12859-025-06249-3\nTitle: GeneSetCluster 2.0: a comprehensive toolset for summarizing and integrating gene-sets analysis\nAbstract: Background Gene-Set Analysis (GSA) is commonly used to analyze high-throughput experiments. However, GSA cannot readily disentangle clusters or pathways due to redundancies in upstream knowledge bases, which hinders comprehensive exploration and interpretation of biological findings. To address this challenge, we developed GeneSetCluster, an R package designed to summarize and integrate GSA results. Over time, we and users as well identified limitations in the original version, such as difficulties in managing redundancies across multiple gene-sets, large computational times, and its lack of accessibility for users without programming expertise. Results We present GeneSetCluster 2.0, a comprehensive upgrade that delivers methodological, computational, interpretative, and user-experience enhancements. Methodologically, GeneSetCluster 2.0 introduces a novel approach to address duplicated gene-sets and implements a seriation-based clustering algorithm that reorders results, aiding pattern identification. Computationally, the package is optimized for parallel processing, significantly reducing execution time. GeneSetCluster 2.0 enhances cluster annotations by associating clusters with relevant tissues and biological processes to improve biological interpretation, particularly for human and mouse data. To broaden accessibility, we have developed a user-friendly web application enabling non-programmers to use it. This version also ensures seamless integration between the R package, catering to users with programming expertise, and the web application for broader audiences. We evaluated the updates in a single-cell RNA public dataset. Conclusion GeneSetCluster 2.0 offers substantial improvements over its predecessor. Furthermore, by bridging the gap between bioinformaticians and clinicians in multidisciplinary teams, GeneSetCluster 2.0 facilitates collaborative research. The R package and web application, along with detailed installation and usage guides, are available on GitHub ( https://github.com/TranslationalBioinformaticsUnit/GeneSetCluster2.0 ), and the web application can be accessed at https://translationalbio.shinyapps.io/genesetcluster/ .\n\nDOI: 10.1038/s41598-025-15885-x\nTitle: Semantic web ontology for structured knowledge representation and clinical decision support in eye diseases\nAbstract: Vision is a vital sense that allows people to interact with their surroundings and carry out tasks efficiently while maintaining safety and independence. At least 2.2 billion people globally suffer from blindness or vision impairment, of which more than 1 billion cases are avoidable or untreated because they lack access to eye care services. In ophthalmology, there are numerous challenges in knowledge organization and management, mainly due to the complexity of eye diseases. Ontologies are used as excellent tools for organizing and managing complicated information due to their structured representations of domain knowledge and to make data more findable, accessible, interoperable, and reusable. We have developed an ontology, that is, Eye Disease Ontology (EDO), for the most common eye diseases as a resource that helps in data extraction and analysis for the general public and medical professionals. EDO is a comprehensive and systematic knowledge representation system that categorizes and organizes information about commonly occurring eye diseases such as cataracts, glaucoma, age-related macular degeneration, etc, and connects it to vital details such as symptoms, causes, risk factors, diagnostic tests, and treatment options. The significant metrics of EDO include 566 classes, 16 object properties, 12 data properties, and 119 instances. In this study, the ontology of eye diseases has the potential to improve clinical diagnosis, advance research, and enrich medical education, while improving patient care. This ontology was created using the NeOn technique in the Protégé/OWL environment. Several competency questions were created to meet the demands of various stakeholders, and the ontology was validated using SPARQL queries, the Hermit Reasoner, and the OOPS Pitfalls Scanner. In addition, we develop comprehensive documentation for EDO to promote reuse and emphasise the importance of reuse in future applications.\n\n"},"children":[],"identifier":"jed1erhxysh3-outputs-0","html_id":"jed1erhxysh3-outputs-0","key":"VZgEdOqzxk"}],"identifier":"jed1erhxysh3-outputs","html_id":"jed1erhxysh3-outputs","key":"EDdcp5vJBU"}],"identifier":"jed1erhxysh3","label":"JeD1ERHxYSH3","html_id":"jed1erhxysh3","key":"Pzt2PY1Hr7"},{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tak84tifjRce","outputId":"836aae9f-0c67-40e6-f53f-3e5d985c91de"},"children":[{"type":"code","lang":"python","executable":true,"value":"import requests\nimport csv\n\n# Silahkan membuat api key dari https://dev.springernature.com/#api\napi_key = \"6812f052d58306c4316bac37cf837912\"\nkeyword = \"web mining\"\n\nurl = \"https://api.springernature.com/meta/v2/json\"\nparams = {\n    \"q\": f\"keyword:{keyword}\",\n    \"api_key\": api_key,\n    \"p\": 10   # jumlah hasil per halaman\n}\n\nresponse = requests.get(url, params=params)\n\nif response.status_code == 200:\n    data = response.json()\n    total = data['result'][0]['total']\n    print(f\"Total hasil: {total}\\n\")\n\n    # Simpan ke CSV\n    with open(\"springer_results.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n        writer = csv.writer(file)\n        # Header kolom\n        writer.writerow([\"DOI\", \"Title\", \"Abstract\"])\n\n        # Data hasil crawling\n        for record in data['records']:\n            doi = record.get('doi', 'N/A')\n            title = record.get('title', 'No title')\n            abstract = record.get('abstract', 'No abstract')\n\n            # Tulis ke file CSV\n            writer.writerow([doi, title, abstract])\n\n            # Print ke console juga\n            print(f\"DOI: {doi}\")\n            print(f\"Title: {title}\")\n            print(f\"Abstract: {abstract}\\n\")\n\n    print(\"✅ Data berhasil disimpan ke springer_results.csv\")\n\nelse:\n    print(\"Error:\", response.status_code, response.text)","identifier":"tak84tifjrce-code","enumerator":"3","html_id":"tak84tifjrce-code","key":"wwhMvtxhmf"},{"type":"outputs","id":"dpZ7tYHmUqiibgDZq_2QC","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Total hasil: 7596\n\nDOI: 10.1007/978-3-031-89518-0_1\nTitle: On the Centrality of Web Trackers: Assessing Its Potential for Automated Detection\nAbstract: For the past 20 years, web tracking has raised worries among privacy advocates and authorities responsible for data protection. Researchers have proposed several machine learning-driven remedies to identify Web trackers in an automated manner. While those have displayed potential, they have primarily remained as proofs-of-concept. This work extends on t.ex-Graph outlined in our previous work [ 36 ]. The aim of this model is to distinguish benign from tracking hosts by considering their centrality in the network, and data flows to them. Based on the results of our previous work, we abandoned the SLD-based approach. Consequently, we made slight modifications to the feature vector. Our classifier’s performance is comparable to its original version, and we tested its cross-browser and longitudinal performance. Our results indicate that while the cross-browser performance significantly decreases, the longitudinal performance maintains a high level.\n\nDOI: 10.1007/978-3-031-93257-1_6\nTitle: Adaptive Web API Recommendation via Matching Service Clusters and Mashup Requirement\nAbstract: With the rapid proliferation of Web services and Web APIs, recommendation systems can effectively address the issue of information overload and alleviate the burden of meaningless filtering. Existing approaches can help filtering appropriate Web services for mashup creation, however, they often fall short of developers’ different and personalized needs by recommending only a fixed number of APIs and lack precision in aligning mashup requirements across all categories. To solve the above issue, this paper introduces a novel Web service recommendation framework called AWAR for mashup creation, which focuses on the matching strategy between mashup requirements and Web APIs, and enhances recommendation effectiveness by integrating natural language processing, optimization algorithms, and deep learning. Extensive experiments conducted on large-scale real datasets demonstrate that the proposed approach receives superior recommendation results on multiple evaluation metrics compared to advanced competing baselines.\n\nDOI: 10.1007/978-3-031-94280-8_1\nTitle: IoT-Enabled Child Monitoring and Control System via Web Interface\nAbstract: In this fast-paced society, working parents nowadays find it challenging to juggle childcare with their busy schedules. In light of this, a novel infant management system utilizing the Internet of Things has developed. This system functions by using sophisticated technology to automate tasks hence ensuring babies safety and comfort. The major features are sound sensor that results into automatic rocking cradle; integrated speaker which can play lullabies to a baby. The system is continuously monitored for its temperature and humidity by sensors sending the caregiver a summary notification about their vicinity while motion detectors are present alongside it. While a rain sensor identifies wet diapers, a DC fan keeps the room at a suitable temperature. Components like cradle swing, DC fan operations, or even playing of lullabies can be remotely controlled through web interface. It implies that one can easily control his infant immediate surroundings from anywhere around the world without hassle. The proposed system utilizes ESP32 technology making use of ESP32 camera for detecting children via live streaming. This all-inclusive monitoring has provided a new dimension to childcare technology thus relieving anxiety among workers as well as inexperienced parents.\n\nDOI: 10.1007/978-3-032-00350-8_12\nTitle: Ethical Implications of Using AI to Monitor and Regulate Dark Web Activities\nAbstract: The dark web continues to attract more illegal activities, and law enforcement and societal security face significant challenges. AI, though strong for monitoring and regulation, does raise critical ethical concerns concerning the use of these technologies for that purpose. This study considers the ethical aspects of AI systems for policing the dark web, including the trade-off between security and privacy, risks of bias and discrimination, and accountability in automated decision-making. Through a mixed-method approach involving both legal analysis, expert interviews, and case studies of existing AI-driven dark web monitoring systems, we identify central ethical challenges and potential mitigation strategies. In doing so, our results will reflect how AI may strengthen efficiency and effectiveness in terms of dark web policing, which equally result in the violation of user privacy, the perpetuation of systemic biases, and a lack of transparency in its operations. Ultimately, we conclude that proper use of AI in monitoring dark webs requires a robust governance framework, one that can ensure accountability, legitimacy, and respect for civil liberties. Such a framework must build on robust, clear guidelines for collecting and utilizing information, regular audits of bias, effectiveness, and mechanisms for human oversight and intervention. Given such measures, chances for using AI in the fight against crimes committed on the dark web are securely positioned within the right and constitutional means to protect the rights of individuals in this age of digitization.\n\nDOI: 10.1007/978-3-031-97144-0_6\nTitle: IRIS: Rapid Curation Framework for Iterative Improvement of Noisy Named Entity Annotations\nAbstract: We propose IRIS (IteRative Improvement dS-ner), a rapid curation framework for the iterative improvement of noisy named entity annotations. The framework aims to provide an efficient and rapid method for curating noisy entity annotations initially made by distantly supervised named entity recognition (DS-NER). Unlike many existing entity annotation tools, which focus primarily on annotation from scratch, IRIS is designed to provide more efficient methods for improving entity annotations initially generated by DS-NER. This is enabled by robust annotation search capabilities and the automatic annotation capabilities suggested by the NER model, which is initialized with the DS-NER model and later incrementally updated during annotation. We also adopt Active Learning (AL), which allows curators to work with documents suggested by the system, rather than manually selecting them. This work also analyzes the trade-offs among different strategies for iteratively updating the NER model, such as selecting training samples and the strategies for fine-tuning the new NER model based on the previous model or training it from scratch.\n\nDOI: 10.1007/s10115-025-02444-z\nTitle: Cross-modal associated learning with spatial–temporal attention for hot topic detection\nAbstract: With the explosion in the number of web videos, it has become a common practice to detect hot topics with web videos. However, each video clip contains multiple patterns, in which object actions might only appear in specific spatial areas or specific time periods, posing a huge challenge for web video hot topic detection. Fortunately, visual information during a specific time period and area will significantly enhance the rapid capture of key information, which is particularly important for detecting hot topics. Therefore, we propose a cross-modal associated learning method with spatial–temporal attention. It can automatically select discriminative time segments to detect hot topics by focusing on spatial regions with rich information. Firstly, after focusing on important keyframes related to the topic through temporal attention, spatial attention emphasizes the salient regions in the frame, thus incorporating discriminative features at the spatial level. Secondly, after integrating text structure knowledge into text semantic features, it can adaptively learn the weights of text features and visual features. Thirdly, adaptive learning of cross-modal fusion weights, achieving mutual guidance between text and visual information in attention dispersed association models to enhance feature learning. Finally, under the constraint of contrast loss, hot topics are detected with the similarity between features. Extensive experiments conducted on web videos from YouTube indicate that our method outperforms 8 leading state-of-the-art methods.\n\nDOI: 10.1007/s40558-025-00327-1\nTitle: A recommender-based web platform to boost tourism in marginal territories\nAbstract: Recommender engines are software applications employed in online tourism information searches to suggest useful content and guide user choices. They represent a significant area of research within the tourism sector, crucially influencing traveler decisions through personalized recommendations. This paper focuses specifically on the Branding4Resilience (B4R) project, whose objective is to promote inner areas, by co-designing virtuous transformations with their inhabitants through novel branding strategies and digital enabling infrastructures. All experiments and assessments described in this study were conducted within the italian area of Sassoferrato, corresponding to the criteria defined by the B4R initiative. The paper introduces a dedicated web platform aimed at enhancing tourism by directing attention towards inland destinations and networking opportunities. The platform enables local providers of tourism-related services, such as guides, event organizers, and restaurateurs, to connect effectively with tourists seeking distinctive experiences. By facilitating interactions, the platform promotes collaboration, innovation, and the co-creation of personalized experiences, transforming tourists into active participants and contributors. To evaluate user experience, perceived usefulness, and innovation of the platform, we analyzed user responses to a structured questionnaire, which combined frequently addressed questions from existing literature with newly developed items specific to our platform. Constructs included tourist platform usage, perceived utility, content quality, design and usability, and innovative elements. The implemented algorithm demonstrated an average sensitivity of 79.74%, highlighting its efficacy in providing relevant suggestions to the platform’s “consumers” users.\n\nDOI: 10.1186/s40793-025-00772-9\nTitle: Protozoa-driven micro-food webs shaping carbon and nitrogen cycling in reservoir ecosystems\nAbstract: Protozoa-driven micro-food webs are pivotal regulators of microbial community structure and carbon–nitrogen cycling. By mediating trophic cascades that regulate bacterial and algal populations, protozoa influence nutrient remineralization and energy flow. Their regulation is crucial for stabilizing biogeochemical processes and preventing harmful algal blooms. However, little is known about the detailed relationship between the traits of micro-food webs and carbon/nitrogen cycling processes. Using metagenomic data, we investigated the complexity and stability of micro-food webs in three distinct zones of the Fenhe Reservoir—the inflow river zone, shallow wetland, and deep-water zone—to assess their impacts on carbon and nitrogen cycling. Our findings revealed distinct spatial patterns in micro-food web complexity and stability, with the highest diversity and interaction density in inflowing river zones and a gradual simplification towards deep-water zones. Functional gene analysis shows significant differences in carbon degradation, fixation pathways, and nitrogen transformation processes, with shallow waters exhibiting strong microbial-mediated nitrification and denitrification, while deep waters rely on anaerobic nitrogen reduction pathways. Partial least squares path modeling (PLS-PM) indicated that protozoan-driven micro-food web structures regulate microbial functional differentiation, thereby influencing carbon and nitrogen cycle. Additionally, environmental parameters such as organic carbon concentration and nitrogen availability significantly shape microbial interactions and biogeochemical transformations. These findings highlight the intricate relationship between microbial community composition, food web stability, and elemental cycling, providing critical insights for reservoir ecosystem management and water quality optimization.\n\nDOI: 10.1186/s12859-025-06249-3\nTitle: GeneSetCluster 2.0: a comprehensive toolset for summarizing and integrating gene-sets analysis\nAbstract: Background Gene-Set Analysis (GSA) is commonly used to analyze high-throughput experiments. However, GSA cannot readily disentangle clusters or pathways due to redundancies in upstream knowledge bases, which hinders comprehensive exploration and interpretation of biological findings. To address this challenge, we developed GeneSetCluster, an R package designed to summarize and integrate GSA results. Over time, we and users as well identified limitations in the original version, such as difficulties in managing redundancies across multiple gene-sets, large computational times, and its lack of accessibility for users without programming expertise. Results We present GeneSetCluster 2.0, a comprehensive upgrade that delivers methodological, computational, interpretative, and user-experience enhancements. Methodologically, GeneSetCluster 2.0 introduces a novel approach to address duplicated gene-sets and implements a seriation-based clustering algorithm that reorders results, aiding pattern identification. Computationally, the package is optimized for parallel processing, significantly reducing execution time. GeneSetCluster 2.0 enhances cluster annotations by associating clusters with relevant tissues and biological processes to improve biological interpretation, particularly for human and mouse data. To broaden accessibility, we have developed a user-friendly web application enabling non-programmers to use it. This version also ensures seamless integration between the R package, catering to users with programming expertise, and the web application for broader audiences. We evaluated the updates in a single-cell RNA public dataset. Conclusion GeneSetCluster 2.0 offers substantial improvements over its predecessor. Furthermore, by bridging the gap between bioinformaticians and clinicians in multidisciplinary teams, GeneSetCluster 2.0 facilitates collaborative research. The R package and web application, along with detailed installation and usage guides, are available on GitHub ( https://github.com/TranslationalBioinformaticsUnit/GeneSetCluster2.0 ), and the web application can be accessed at https://translationalbio.shinyapps.io/genesetcluster/ .\n\nDOI: 10.1038/s41598-025-15885-x\nTitle: Semantic web ontology for structured knowledge representation and clinical decision support in eye diseases\nAbstract: Vision is a vital sense that allows people to interact with their surroundings and carry out tasks efficiently while maintaining safety and independence. At least 2.2 billion people globally suffer from blindness or vision impairment, of which more than 1 billion cases are avoidable or untreated because they lack access to eye care services. In ophthalmology, there are numerous challenges in knowledge organization and management, mainly due to the complexity of eye diseases. Ontologies are used as excellent tools for organizing and managing complicated information due to their structured representations of domain knowledge and to make data more findable, accessible, interoperable, and reusable. We have developed an ontology, that is, Eye Disease Ontology (EDO), for the most common eye diseases as a resource that helps in data extraction and analysis for the general public and medical professionals. EDO is a comprehensive and systematic knowledge representation system that categorizes and organizes information about commonly occurring eye diseases such as cataracts, glaucoma, age-related macular degeneration, etc, and connects it to vital details such as symptoms, causes, risk factors, diagnostic tests, and treatment options. The significant metrics of EDO include 566 classes, 16 object properties, 12 data properties, and 119 instances. In this study, the ontology of eye diseases has the potential to improve clinical diagnosis, advance research, and enrich medical education, while improving patient care. This ontology was created using the NeOn technique in the Protégé/OWL environment. Several competency questions were created to meet the demands of various stakeholders, and the ontology was validated using SPARQL queries, the Hermit Reasoner, and the OOPS Pitfalls Scanner. In addition, we develop comprehensive documentation for EDO to promote reuse and emphasise the importance of reuse in future applications.\n\n✅ Data berhasil disimpan ke springer_resultss.csv\n"},"children":[],"identifier":"tak84tifjrce-outputs-0","html_id":"tak84tifjrce-outputs-0","key":"T7V4bPggyh"}],"identifier":"tak84tifjrce-outputs","html_id":"tak84tifjrce-outputs","key":"x5Swqu6X8P"}],"identifier":"tak84tifjrce","label":"tak84tifjRce","html_id":"tak84tifjrce","key":"PbJrLy4Yp8"},{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FmApwghM6qdc","outputId":"e9bd38ee-4bde-4146-d624-c908c627d61b"},"children":[{"type":"code","lang":"python","executable":true,"value":"import requests\n# Silahkan membuat api key dari https://dev.springernature.com/#api\napi_key = \"6812f052d58306c4316bac37cf837912\"\nkeyword = \"web usage mining\"\n\nurl = \"https://api.springernature.com/meta/v2/json\"\nparams = {\n    \"q\": f\"keyword:{keyword}\",\n    \"api_key\": api_key,\n    \"p\": 10\n}\n\nresponse = requests.get(url, params=params)\n\nif response.status_code == 200:\n    data = response.json()\n    print(f\"Total hasil: {data['result'][0]['total']}\\n\")\n    for record in data['records']:\n        doi = record.get('doi', 'N/A')\n        title = record.get('title', 'No title')\n        abstract = record.get('abstract', 'No abstract')\n        print(f\"DOI: {doi}\")\n        print(f\"Title: {title}\")\n        print(f\"Abstract: {abstract}\\n\")\nelse:\n    print(\"Error:\", response.status_code, response.text)","identifier":"fmapwghm6qdc-code","enumerator":"4","html_id":"fmapwghm6qdc-code","key":"Y5DwNgf5z4"},{"type":"outputs","id":"PtIkP39fPizlBb4LSfl75","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Total hasil: 3187\n\nDOI: 10.1007/978-3-031-89518-0_1\nTitle: On the Centrality of Web Trackers: Assessing Its Potential for Automated Detection\nAbstract: For the past 20 years, web tracking has raised worries among privacy advocates and authorities responsible for data protection. Researchers have proposed several machine learning-driven remedies to identify Web trackers in an automated manner. While those have displayed potential, they have primarily remained as proofs-of-concept. This work extends on t.ex-Graph outlined in our previous work [ 36 ]. The aim of this model is to distinguish benign from tracking hosts by considering their centrality in the network, and data flows to them. Based on the results of our previous work, we abandoned the SLD-based approach. Consequently, we made slight modifications to the feature vector. Our classifier’s performance is comparable to its original version, and we tested its cross-browser and longitudinal performance. Our results indicate that while the cross-browser performance significantly decreases, the longitudinal performance maintains a high level.\n\nDOI: 10.1007/978-3-031-93257-1_6\nTitle: Adaptive Web API Recommendation via Matching Service Clusters and Mashup Requirement\nAbstract: With the rapid proliferation of Web services and Web APIs, recommendation systems can effectively address the issue of information overload and alleviate the burden of meaningless filtering. Existing approaches can help filtering appropriate Web services for mashup creation, however, they often fall short of developers’ different and personalized needs by recommending only a fixed number of APIs and lack precision in aligning mashup requirements across all categories. To solve the above issue, this paper introduces a novel Web service recommendation framework called AWAR for mashup creation, which focuses on the matching strategy between mashup requirements and Web APIs, and enhances recommendation effectiveness by integrating natural language processing, optimization algorithms, and deep learning. Extensive experiments conducted on large-scale real datasets demonstrate that the proposed approach receives superior recommendation results on multiple evaluation metrics compared to advanced competing baselines.\n\nDOI: 10.1007/s10115-025-02444-z\nTitle: Cross-modal associated learning with spatial–temporal attention for hot topic detection\nAbstract: With the explosion in the number of web videos, it has become a common practice to detect hot topics with web videos. However, each video clip contains multiple patterns, in which object actions might only appear in specific spatial areas or specific time periods, posing a huge challenge for web video hot topic detection. Fortunately, visual information during a specific time period and area will significantly enhance the rapid capture of key information, which is particularly important for detecting hot topics. Therefore, we propose a cross-modal associated learning method with spatial–temporal attention. It can automatically select discriminative time segments to detect hot topics by focusing on spatial regions with rich information. Firstly, after focusing on important keyframes related to the topic through temporal attention, spatial attention emphasizes the salient regions in the frame, thus incorporating discriminative features at the spatial level. Secondly, after integrating text structure knowledge into text semantic features, it can adaptively learn the weights of text features and visual features. Thirdly, adaptive learning of cross-modal fusion weights, achieving mutual guidance between text and visual information in attention dispersed association models to enhance feature learning. Finally, under the constraint of contrast loss, hot topics are detected with the similarity between features. Extensive experiments conducted on web videos from YouTube indicate that our method outperforms 8 leading state-of-the-art methods.\n\nDOI: 10.1007/s40558-025-00327-1\nTitle: A recommender-based web platform to boost tourism in marginal territories\nAbstract: Recommender engines are software applications employed in online tourism information searches to suggest useful content and guide user choices. They represent a significant area of research within the tourism sector, crucially influencing traveler decisions through personalized recommendations. This paper focuses specifically on the Branding4Resilience (B4R) project, whose objective is to promote inner areas, by co-designing virtuous transformations with their inhabitants through novel branding strategies and digital enabling infrastructures. All experiments and assessments described in this study were conducted within the italian area of Sassoferrato, corresponding to the criteria defined by the B4R initiative. The paper introduces a dedicated web platform aimed at enhancing tourism by directing attention towards inland destinations and networking opportunities. The platform enables local providers of tourism-related services, such as guides, event organizers, and restaurateurs, to connect effectively with tourists seeking distinctive experiences. By facilitating interactions, the platform promotes collaboration, innovation, and the co-creation of personalized experiences, transforming tourists into active participants and contributors. To evaluate user experience, perceived usefulness, and innovation of the platform, we analyzed user responses to a structured questionnaire, which combined frequently addressed questions from existing literature with newly developed items specific to our platform. Constructs included tourist platform usage, perceived utility, content quality, design and usability, and innovative elements. The implemented algorithm demonstrated an average sensitivity of 79.74%, highlighting its efficacy in providing relevant suggestions to the platform’s “consumers” users.\n\nDOI: 10.1186/s12859-025-06249-3\nTitle: GeneSetCluster 2.0: a comprehensive toolset for summarizing and integrating gene-sets analysis\nAbstract: Background Gene-Set Analysis (GSA) is commonly used to analyze high-throughput experiments. However, GSA cannot readily disentangle clusters or pathways due to redundancies in upstream knowledge bases, which hinders comprehensive exploration and interpretation of biological findings. To address this challenge, we developed GeneSetCluster, an R package designed to summarize and integrate GSA results. Over time, we and users as well identified limitations in the original version, such as difficulties in managing redundancies across multiple gene-sets, large computational times, and its lack of accessibility for users without programming expertise. Results We present GeneSetCluster 2.0, a comprehensive upgrade that delivers methodological, computational, interpretative, and user-experience enhancements. Methodologically, GeneSetCluster 2.0 introduces a novel approach to address duplicated gene-sets and implements a seriation-based clustering algorithm that reorders results, aiding pattern identification. Computationally, the package is optimized for parallel processing, significantly reducing execution time. GeneSetCluster 2.0 enhances cluster annotations by associating clusters with relevant tissues and biological processes to improve biological interpretation, particularly for human and mouse data. To broaden accessibility, we have developed a user-friendly web application enabling non-programmers to use it. This version also ensures seamless integration between the R package, catering to users with programming expertise, and the web application for broader audiences. We evaluated the updates in a single-cell RNA public dataset. Conclusion GeneSetCluster 2.0 offers substantial improvements over its predecessor. Furthermore, by bridging the gap between bioinformaticians and clinicians in multidisciplinary teams, GeneSetCluster 2.0 facilitates collaborative research. The R package and web application, along with detailed installation and usage guides, are available on GitHub ( https://github.com/TranslationalBioinformaticsUnit/GeneSetCluster2.0 ), and the web application can be accessed at https://translationalbio.shinyapps.io/genesetcluster/ .\n\nDOI: 10.1038/s41598-025-15885-x\nTitle: Semantic web ontology for structured knowledge representation and clinical decision support in eye diseases\nAbstract: Vision is a vital sense that allows people to interact with their surroundings and carry out tasks efficiently while maintaining safety and independence. At least 2.2 billion people globally suffer from blindness or vision impairment, of which more than 1 billion cases are avoidable or untreated because they lack access to eye care services. In ophthalmology, there are numerous challenges in knowledge organization and management, mainly due to the complexity of eye diseases. Ontologies are used as excellent tools for organizing and managing complicated information due to their structured representations of domain knowledge and to make data more findable, accessible, interoperable, and reusable. We have developed an ontology, that is, Eye Disease Ontology (EDO), for the most common eye diseases as a resource that helps in data extraction and analysis for the general public and medical professionals. EDO is a comprehensive and systematic knowledge representation system that categorizes and organizes information about commonly occurring eye diseases such as cataracts, glaucoma, age-related macular degeneration, etc, and connects it to vital details such as symptoms, causes, risk factors, diagnostic tests, and treatment options. The significant metrics of EDO include 566 classes, 16 object properties, 12 data properties, and 119 instances. In this study, the ontology of eye diseases has the potential to improve clinical diagnosis, advance research, and enrich medical education, while improving patient care. This ontology was created using the NeOn technique in the Protégé/OWL environment. Several competency questions were created to meet the demands of various stakeholders, and the ontology was validated using SPARQL queries, the Hermit Reasoner, and the OOPS Pitfalls Scanner. In addition, we develop comprehensive documentation for EDO to promote reuse and emphasise the importance of reuse in future applications.\n\nDOI: 10.1007/s12145-025-01982-y\nTitle: Four decades of trends in invisible gold research: a web of science-based bibliometric analysis (1985–2024)\nAbstract: Invisible gold research is essential for understanding gold mineralization, overcoming analytical limitations, and addressing the technological bottlenecks in the economic extraction of refractory gold, thereby unlocking the potential of these deposits and their tailings. To assess research trends and demand, this study analyzed 1300 records from the Web of Science database (1985–2024) using the cross-disciplinary publication index (CDPI), the co-authorship model, and the technology-economic linkage model (TELM), with visualizations generated via VOSviewer and Microsoft Excel. The analysis reveals a 65% increase in publications between 2015 and 2021, with a peak of 98 papers in 2021. Articles constitute the majority (84.6%), followed by conference proceedings (9.8%) and reviews (3.9%). Interdisciplinary contributions surged by 40% after 2015, particularly in “materials science”, as indicated by a high CDPI of 0.81; while a discipline-pair co-occurrence score between “materials science and nanotechnology” reached a CDPI of 0.75. Notably, the CDPI model reveals that 68% of advancements in extraction technologies between 2015 and 2024 originated from nanoscale-oriented invisible gold research published in geoscience-focused journals employing advanced nanotechnologies. Furthermore, the TELM framework identifies that between 2021 and 2024, high gold prices—ranging from $1,798/oz to $1,940/oz—were well correlated (R^2 = 0.89) with publication counts, which remained consistently high at 94 to 98 papers annually. Two key methodological trends identified in this study for invisible gold research are: (1) the development of environmentally friendly extraction techniques, including biooxidation or thiosulfate leaching, and advanced pre-treatment processes; and (2) the adoption of high-precision analytical tools such as LA-ICP-MS, SIMS, and TIMA-X, which have significantly enhanced nanoscale gold detection and characterization. This methodological progress is further supported by the increase in annual research funding—from approximately $2–5 million when gold prices averaged $370/oz (1985–2000), to $10–30 million at around $700/oz (2001–2015), and up to $50–120 million as prices exceeded $1,500/oz (2016–2024)—demonstrating a strong positive association between rising gold prices and investment in invisible gold research. The findings reveal key trends in invisible gold research, demonstrating that Web of Science data, VOSviewer visualizations, and the CDPI and TELM frameworks provide a more reliable basis for identifying interdisciplinary patterns and economic drivers. They highlight not only scientific progress in mineral exploration, extraction technologies, and metallurgical methods, but also persistent challenges in the economic recovery of invisible gold. These insights offer a roadmap for future research, industrial application, and international collaboration.\n\nDOI: 10.1007/s41060-023-00483-9\nTitle: Artificial intelligence trend analysis in German business and politics: a web mining approach\nAbstract: Current research on trend detection in artificial intelligence (AI) mainly concerns academic data sources and industrial applications of AI. However, we argue that industrial trends are influenced by public perception and political decisions (e.g., through industry subsidies and grants) and should be reflected in political data sources. To investigate this hypothesis, we examine the AI trend development in German business and politics from 1998 to 2020. Therefore, we propose a web mining approach to collect a novel data set consisting of business and political data sources combining 1.07 million articles and documents. We identify 246 AI-related buzzwords extracted from various glossaries. We use them to conduct an extensive trend detection and analysis study on the collected data using machine learning-based approaches. This study successfully detects an AI trend and follows its evolution in business and political data sources over the past two decades. Moreover, we find a faster adoption of AI in business than in politics, with a considerable increase in policy discourse in recent years. Finally, we show that the collected data can be used for trend detection besides AI-related topics using topic clustering and the COVID-19 pandemic as examples.\n\nDOI: 10.1007/s11030-025-11196-5\nTitle: Titania: an integrated tool for in silico molecular property prediction and NAM-based modeling\nAbstract: Advances in drug discovery and material design rely heavily on in silico analysis of extensive compound datasets and accurate assessment of their properties and activities through computational methods. Efficient and reliable prediction of molecular properties is crucial for rational compound design in the chemical industry. To address this need, we have developed predictive models for nine key properties, including the octanol/water partition coefficient, water solubility, experimental hydration free energy in water, vapor pressure, boiling point, cytotoxicity, mutagenicity, blood–brain barrier permeability, and bioconcentration factor. These models have demonstrated high predictive accuracy and have undergone thorough validation in accordance with OECD test guidelines. The models are seamlessly integrated into the Enalos Cloud Platform through Titania ( https://enaloscloud.novamechanics.com/EnalosWebApps/titania/ ), a comprehensive web-based application designed to democratize access to advanced computational tools. Titania features an intuitive, user-friendly interface, allowing researchers, regardless of computational expertise, to easily employ models for property prediction of novel compounds. The platform enables informed decision-making and supports innovation in drug discovery and material design. We aspire for this tool to become a valuable resource for the scientific community, enhancing both the efficiency and accuracy of property and toxicity predictions.\n\nDOI: 10.1007/s10639-025-13523-7\nTitle: Student translators’ web-based vs. GenAI-based information-seeking behavior in translation process: A comparative study\nAbstract: The rise of Generative AI (GenAI) tools, such as ChatGPT, is transforming translators’ information-seeking behavior (ISB), traditionally centered on web search. This study compares student translators’ ISB in web-based and GenAI-driven contexts using a literature-informed ISB analytical framework, developed from a systematic review of existing ISB theories and models, with a focus on time-related, query/prompt-related, and process-related aspects. To compare these two conditions, twenty-four student translators completed two tasks under each condition. Their on-screen activities were recorded and analyzed using a comparative approach, which involved evaluating differences in the three aforementioned aspects. The data were collected through screen recording, coded using NVivo, and analyzed using mixed-effects regression models to assess behavioral patterns and determine how these aspects vary between web-based and GenAI-based ISB. Findings reveal distinct patterns: 1) Time-related: GenAI-based ISB takes longer, with extended information-seeking durations, whereas web-based ISB is quicker and more efficient; 2) Query/prompt-related: Both focus on source comprehension, but GenAI-based ISB addresses complex, segment-level tasks with broader objectives, whereas web-based ISB handles immediate, word-level issues with narrower goals; 3) Process-related: GenAI-based ISB is dynamic, involving frequent switching with less depth, while web-based ISB is more linear and structured, supporting deeper exploration within online resources. Overall, GenAI-based ISB is dynamic and interactive, allowing broader exploration of translation tasks, yet it may sacrifice depth and lead to increased reliance. In contrast, web-based ISB is more structured and precise, well-suited for word-level tasks, but lacks the flexibility for more complex translation challenges. Theoretically, this study extends ISB frameworks by demonstrating GenAI’s dynamic yet reliance-prone model, while pedagogically, it highlights the need for balancing GenAI and web-based tools and fostering critical evaluation through multi-step tasks, error analysis, and cross-verification.\n\n"},"children":[],"identifier":"fmapwghm6qdc-outputs-0","html_id":"fmapwghm6qdc-outputs-0","key":"hohFs5qCbo"}],"identifier":"fmapwghm6qdc-outputs","html_id":"fmapwghm6qdc-outputs","key":"jpScsNm25H"}],"identifier":"fmapwghm6qdc","label":"FmApwghM6qdc","html_id":"fmapwghm6qdc","key":"HrwqPJlphG"},{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T9lthGI065OC","outputId":"61142215-2062-44ff-fc7d-2024c774ae33"},"children":[{"type":"code","lang":"python","executable":true,"value":"import requests\nimport csv\n\n# Silahkan membuat api key dari https://dev.springernature.com/#api\napi_key = \"6812f052d58306c4316bac37cf837912\"\nkeyword = \"web usage mining\"\n\nurl = \"https://api.springernature.com/meta/v2/json\"\nparams = {\n    \"q\": f\"keyword:{keyword}\",\n    \"api_key\": api_key,\n    \"p\": 10   # jumlah hasil per halaman\n}\n\nresponse = requests.get(url, params=params)\n\nif response.status_code == 200:\n    data = response.json()\n    total = data['result'][0]['total']\n    print(f\"Total hasil: {total}\\n\")\n\n    # Simpan ke CSV\n    with open(\"springer_results_web_usage_mining.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n        writer = csv.writer(file)\n        # Header kolom\n        writer.writerow([\"DOI\", \"Title\", \"Abstract\"])\n\n        # Data hasil crawling\n        for record in data['records']:\n            doi = record.get('doi', 'N/A')\n            title = record.get('title', 'No title')\n            abstract = record.get('abstract', 'No abstract')\n\n            # Tulis ke file CSV\n            writer.writerow([doi, title, abstract])\n\n            # Print ke console juga\n            print(f\"DOI: {doi}\")\n            print(f\"Title: {title}\")\n            print(f\"Abstract: {abstract}\\n\")\n\n    print(\" Data berhasil disimpan ke springer_results_web_usage_mining.csv\")\n\nelse:\n    print(\"Error:\", response.status_code, response.text)","identifier":"t9lthgi065oc-code","enumerator":"5","html_id":"t9lthgi065oc-code","key":"PsPyEw4LoY"},{"type":"outputs","id":"nYsNvlcshjGQcB31_pLSo","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Total hasil: 3187\n\nDOI: 10.1007/978-3-031-89518-0_1\nTitle: On the Centrality of Web Trackers: Assessing Its Potential for Automated Detection\nAbstract: For the past 20 years, web tracking has raised worries among privacy advocates and authorities responsible for data protection. Researchers have proposed several machine learning-driven remedies to identify Web trackers in an automated manner. While those have displayed potential, they have primarily remained as proofs-of-concept. This work extends on t.ex-Graph outlined in our previous work [ 36 ]. The aim of this model is to distinguish benign from tracking hosts by considering their centrality in the network, and data flows to them. Based on the results of our previous work, we abandoned the SLD-based approach. Consequently, we made slight modifications to the feature vector. Our classifier’s performance is comparable to its original version, and we tested its cross-browser and longitudinal performance. Our results indicate that while the cross-browser performance significantly decreases, the longitudinal performance maintains a high level.\n\nDOI: 10.1007/978-3-031-93257-1_6\nTitle: Adaptive Web API Recommendation via Matching Service Clusters and Mashup Requirement\nAbstract: With the rapid proliferation of Web services and Web APIs, recommendation systems can effectively address the issue of information overload and alleviate the burden of meaningless filtering. Existing approaches can help filtering appropriate Web services for mashup creation, however, they often fall short of developers’ different and personalized needs by recommending only a fixed number of APIs and lack precision in aligning mashup requirements across all categories. To solve the above issue, this paper introduces a novel Web service recommendation framework called AWAR for mashup creation, which focuses on the matching strategy between mashup requirements and Web APIs, and enhances recommendation effectiveness by integrating natural language processing, optimization algorithms, and deep learning. Extensive experiments conducted on large-scale real datasets demonstrate that the proposed approach receives superior recommendation results on multiple evaluation metrics compared to advanced competing baselines.\n\nDOI: 10.1007/s10115-025-02444-z\nTitle: Cross-modal associated learning with spatial–temporal attention for hot topic detection\nAbstract: With the explosion in the number of web videos, it has become a common practice to detect hot topics with web videos. However, each video clip contains multiple patterns, in which object actions might only appear in specific spatial areas or specific time periods, posing a huge challenge for web video hot topic detection. Fortunately, visual information during a specific time period and area will significantly enhance the rapid capture of key information, which is particularly important for detecting hot topics. Therefore, we propose a cross-modal associated learning method with spatial–temporal attention. It can automatically select discriminative time segments to detect hot topics by focusing on spatial regions with rich information. Firstly, after focusing on important keyframes related to the topic through temporal attention, spatial attention emphasizes the salient regions in the frame, thus incorporating discriminative features at the spatial level. Secondly, after integrating text structure knowledge into text semantic features, it can adaptively learn the weights of text features and visual features. Thirdly, adaptive learning of cross-modal fusion weights, achieving mutual guidance between text and visual information in attention dispersed association models to enhance feature learning. Finally, under the constraint of contrast loss, hot topics are detected with the similarity between features. Extensive experiments conducted on web videos from YouTube indicate that our method outperforms 8 leading state-of-the-art methods.\n\nDOI: 10.1007/s40558-025-00327-1\nTitle: A recommender-based web platform to boost tourism in marginal territories\nAbstract: Recommender engines are software applications employed in online tourism information searches to suggest useful content and guide user choices. They represent a significant area of research within the tourism sector, crucially influencing traveler decisions through personalized recommendations. This paper focuses specifically on the Branding4Resilience (B4R) project, whose objective is to promote inner areas, by co-designing virtuous transformations with their inhabitants through novel branding strategies and digital enabling infrastructures. All experiments and assessments described in this study were conducted within the italian area of Sassoferrato, corresponding to the criteria defined by the B4R initiative. The paper introduces a dedicated web platform aimed at enhancing tourism by directing attention towards inland destinations and networking opportunities. The platform enables local providers of tourism-related services, such as guides, event organizers, and restaurateurs, to connect effectively with tourists seeking distinctive experiences. By facilitating interactions, the platform promotes collaboration, innovation, and the co-creation of personalized experiences, transforming tourists into active participants and contributors. To evaluate user experience, perceived usefulness, and innovation of the platform, we analyzed user responses to a structured questionnaire, which combined frequently addressed questions from existing literature with newly developed items specific to our platform. Constructs included tourist platform usage, perceived utility, content quality, design and usability, and innovative elements. The implemented algorithm demonstrated an average sensitivity of 79.74%, highlighting its efficacy in providing relevant suggestions to the platform’s “consumers” users.\n\nDOI: 10.1186/s12859-025-06249-3\nTitle: GeneSetCluster 2.0: a comprehensive toolset for summarizing and integrating gene-sets analysis\nAbstract: Background Gene-Set Analysis (GSA) is commonly used to analyze high-throughput experiments. However, GSA cannot readily disentangle clusters or pathways due to redundancies in upstream knowledge bases, which hinders comprehensive exploration and interpretation of biological findings. To address this challenge, we developed GeneSetCluster, an R package designed to summarize and integrate GSA results. Over time, we and users as well identified limitations in the original version, such as difficulties in managing redundancies across multiple gene-sets, large computational times, and its lack of accessibility for users without programming expertise. Results We present GeneSetCluster 2.0, a comprehensive upgrade that delivers methodological, computational, interpretative, and user-experience enhancements. Methodologically, GeneSetCluster 2.0 introduces a novel approach to address duplicated gene-sets and implements a seriation-based clustering algorithm that reorders results, aiding pattern identification. Computationally, the package is optimized for parallel processing, significantly reducing execution time. GeneSetCluster 2.0 enhances cluster annotations by associating clusters with relevant tissues and biological processes to improve biological interpretation, particularly for human and mouse data. To broaden accessibility, we have developed a user-friendly web application enabling non-programmers to use it. This version also ensures seamless integration between the R package, catering to users with programming expertise, and the web application for broader audiences. We evaluated the updates in a single-cell RNA public dataset. Conclusion GeneSetCluster 2.0 offers substantial improvements over its predecessor. Furthermore, by bridging the gap between bioinformaticians and clinicians in multidisciplinary teams, GeneSetCluster 2.0 facilitates collaborative research. The R package and web application, along with detailed installation and usage guides, are available on GitHub ( https://github.com/TranslationalBioinformaticsUnit/GeneSetCluster2.0 ), and the web application can be accessed at https://translationalbio.shinyapps.io/genesetcluster/ .\n\nDOI: 10.1038/s41598-025-15885-x\nTitle: Semantic web ontology for structured knowledge representation and clinical decision support in eye diseases\nAbstract: Vision is a vital sense that allows people to interact with their surroundings and carry out tasks efficiently while maintaining safety and independence. At least 2.2 billion people globally suffer from blindness or vision impairment, of which more than 1 billion cases are avoidable or untreated because they lack access to eye care services. In ophthalmology, there are numerous challenges in knowledge organization and management, mainly due to the complexity of eye diseases. Ontologies are used as excellent tools for organizing and managing complicated information due to their structured representations of domain knowledge and to make data more findable, accessible, interoperable, and reusable. We have developed an ontology, that is, Eye Disease Ontology (EDO), for the most common eye diseases as a resource that helps in data extraction and analysis for the general public and medical professionals. EDO is a comprehensive and systematic knowledge representation system that categorizes and organizes information about commonly occurring eye diseases such as cataracts, glaucoma, age-related macular degeneration, etc, and connects it to vital details such as symptoms, causes, risk factors, diagnostic tests, and treatment options. The significant metrics of EDO include 566 classes, 16 object properties, 12 data properties, and 119 instances. In this study, the ontology of eye diseases has the potential to improve clinical diagnosis, advance research, and enrich medical education, while improving patient care. This ontology was created using the NeOn technique in the Protégé/OWL environment. Several competency questions were created to meet the demands of various stakeholders, and the ontology was validated using SPARQL queries, the Hermit Reasoner, and the OOPS Pitfalls Scanner. In addition, we develop comprehensive documentation for EDO to promote reuse and emphasise the importance of reuse in future applications.\n\nDOI: 10.1007/s12145-025-01982-y\nTitle: Four decades of trends in invisible gold research: a web of science-based bibliometric analysis (1985–2024)\nAbstract: Invisible gold research is essential for understanding gold mineralization, overcoming analytical limitations, and addressing the technological bottlenecks in the economic extraction of refractory gold, thereby unlocking the potential of these deposits and their tailings. To assess research trends and demand, this study analyzed 1300 records from the Web of Science database (1985–2024) using the cross-disciplinary publication index (CDPI), the co-authorship model, and the technology-economic linkage model (TELM), with visualizations generated via VOSviewer and Microsoft Excel. The analysis reveals a 65% increase in publications between 2015 and 2021, with a peak of 98 papers in 2021. Articles constitute the majority (84.6%), followed by conference proceedings (9.8%) and reviews (3.9%). Interdisciplinary contributions surged by 40% after 2015, particularly in “materials science”, as indicated by a high CDPI of 0.81; while a discipline-pair co-occurrence score between “materials science and nanotechnology” reached a CDPI of 0.75. Notably, the CDPI model reveals that 68% of advancements in extraction technologies between 2015 and 2024 originated from nanoscale-oriented invisible gold research published in geoscience-focused journals employing advanced nanotechnologies. Furthermore, the TELM framework identifies that between 2021 and 2024, high gold prices—ranging from $1,798/oz to $1,940/oz—were well correlated (R^2 = 0.89) with publication counts, which remained consistently high at 94 to 98 papers annually. Two key methodological trends identified in this study for invisible gold research are: (1) the development of environmentally friendly extraction techniques, including biooxidation or thiosulfate leaching, and advanced pre-treatment processes; and (2) the adoption of high-precision analytical tools such as LA-ICP-MS, SIMS, and TIMA-X, which have significantly enhanced nanoscale gold detection and characterization. This methodological progress is further supported by the increase in annual research funding—from approximately $2–5 million when gold prices averaged $370/oz (1985–2000), to $10–30 million at around $700/oz (2001–2015), and up to $50–120 million as prices exceeded $1,500/oz (2016–2024)—demonstrating a strong positive association between rising gold prices and investment in invisible gold research. The findings reveal key trends in invisible gold research, demonstrating that Web of Science data, VOSviewer visualizations, and the CDPI and TELM frameworks provide a more reliable basis for identifying interdisciplinary patterns and economic drivers. They highlight not only scientific progress in mineral exploration, extraction technologies, and metallurgical methods, but also persistent challenges in the economic recovery of invisible gold. These insights offer a roadmap for future research, industrial application, and international collaboration.\n\nDOI: 10.1007/s41060-023-00483-9\nTitle: Artificial intelligence trend analysis in German business and politics: a web mining approach\nAbstract: Current research on trend detection in artificial intelligence (AI) mainly concerns academic data sources and industrial applications of AI. However, we argue that industrial trends are influenced by public perception and political decisions (e.g., through industry subsidies and grants) and should be reflected in political data sources. To investigate this hypothesis, we examine the AI trend development in German business and politics from 1998 to 2020. Therefore, we propose a web mining approach to collect a novel data set consisting of business and political data sources combining 1.07 million articles and documents. We identify 246 AI-related buzzwords extracted from various glossaries. We use them to conduct an extensive trend detection and analysis study on the collected data using machine learning-based approaches. This study successfully detects an AI trend and follows its evolution in business and political data sources over the past two decades. Moreover, we find a faster adoption of AI in business than in politics, with a considerable increase in policy discourse in recent years. Finally, we show that the collected data can be used for trend detection besides AI-related topics using topic clustering and the COVID-19 pandemic as examples.\n\nDOI: 10.1007/s11030-025-11196-5\nTitle: Titania: an integrated tool for in silico molecular property prediction and NAM-based modeling\nAbstract: Advances in drug discovery and material design rely heavily on in silico analysis of extensive compound datasets and accurate assessment of their properties and activities through computational methods. Efficient and reliable prediction of molecular properties is crucial for rational compound design in the chemical industry. To address this need, we have developed predictive models for nine key properties, including the octanol/water partition coefficient, water solubility, experimental hydration free energy in water, vapor pressure, boiling point, cytotoxicity, mutagenicity, blood–brain barrier permeability, and bioconcentration factor. These models have demonstrated high predictive accuracy and have undergone thorough validation in accordance with OECD test guidelines. The models are seamlessly integrated into the Enalos Cloud Platform through Titania ( https://enaloscloud.novamechanics.com/EnalosWebApps/titania/ ), a comprehensive web-based application designed to democratize access to advanced computational tools. Titania features an intuitive, user-friendly interface, allowing researchers, regardless of computational expertise, to easily employ models for property prediction of novel compounds. The platform enables informed decision-making and supports innovation in drug discovery and material design. We aspire for this tool to become a valuable resource for the scientific community, enhancing both the efficiency and accuracy of property and toxicity predictions.\n\nDOI: 10.1007/s10639-025-13523-7\nTitle: Student translators’ web-based vs. GenAI-based information-seeking behavior in translation process: A comparative study\nAbstract: The rise of Generative AI (GenAI) tools, such as ChatGPT, is transforming translators’ information-seeking behavior (ISB), traditionally centered on web search. This study compares student translators’ ISB in web-based and GenAI-driven contexts using a literature-informed ISB analytical framework, developed from a systematic review of existing ISB theories and models, with a focus on time-related, query/prompt-related, and process-related aspects. To compare these two conditions, twenty-four student translators completed two tasks under each condition. Their on-screen activities were recorded and analyzed using a comparative approach, which involved evaluating differences in the three aforementioned aspects. The data were collected through screen recording, coded using NVivo, and analyzed using mixed-effects regression models to assess behavioral patterns and determine how these aspects vary between web-based and GenAI-based ISB. Findings reveal distinct patterns: 1) Time-related: GenAI-based ISB takes longer, with extended information-seeking durations, whereas web-based ISB is quicker and more efficient; 2) Query/prompt-related: Both focus on source comprehension, but GenAI-based ISB addresses complex, segment-level tasks with broader objectives, whereas web-based ISB handles immediate, word-level issues with narrower goals; 3) Process-related: GenAI-based ISB is dynamic, involving frequent switching with less depth, while web-based ISB is more linear and structured, supporting deeper exploration within online resources. Overall, GenAI-based ISB is dynamic and interactive, allowing broader exploration of translation tasks, yet it may sacrifice depth and lead to increased reliance. In contrast, web-based ISB is more structured and precise, well-suited for word-level tasks, but lacks the flexibility for more complex translation challenges. Theoretically, this study extends ISB frameworks by demonstrating GenAI’s dynamic yet reliance-prone model, while pedagogically, it highlights the need for balancing GenAI and web-based tools and fostering critical evaluation through multi-step tasks, error analysis, and cross-verification.\n\n Data berhasil disimpan ke springer_results_web_usage_mining.csv\n"},"children":[],"identifier":"t9lthgi065oc-outputs-0","html_id":"t9lthgi065oc-outputs-0","key":"SeskbQ7Nzc"}],"identifier":"t9lthgi065oc-outputs","html_id":"t9lthgi065oc-outputs","key":"rdPF6KXwSz"}],"identifier":"t9lthgi065oc","label":"T9lthGI065OC","html_id":"t9lthgi065oc","key":"XiEz6Wuzr7"}],"key":"sZgFXyEIMO"},"references":{"cite":{"order":[],"data":{}}}}